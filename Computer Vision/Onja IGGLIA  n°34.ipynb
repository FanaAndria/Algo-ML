{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# D√©tails de l'√©tudiant\n",
        "### Nom(s)  : RABEMANANTSIMBA\n",
        "### Pr√©nom(s) :Onja Faneva Rinoh\n",
        "### Classe :IGGLIA 4      \n",
        "### Num : 34"
      ],
      "metadata": {
        "id": "K6EHkj63XsUy"
      },
      "id": "K6EHkj63XsUy"
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Vision par Ordinateur avec Keras/TensorFlow : Un Notebook Pratique et Conceptuel\n",
        "\n",
        "Ce notebook a pour objectif de vous guider pas √† pas dans la cr√©ation et l'analyse d'un mod√®le de r√©seau de neurones convolutif (CNN) appliqu√© au jeu de donn√©es CIFAR-10. Chaque √©tape est accompagn√©e d'explications pratiques ainsi que de questions conceptuelles pour renforcer votre compr√©hension des enjeux th√©oriques et pratiques de la vision par ordinateur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape1",
      "metadata": {
        "id": "etape1"
      },
      "source": [
        "## √âtape 1 : Introduction et Configuration de l'Environnement\n",
        "\n",
        "Dans cette √©tape, nous allons configurer notre environnement de travail et importer les biblioth√®ques indispensables pour le deep learning et la manipulation de donn√©es. Nous v√©rifions √©galement la version de TensorFlow pour nous assurer que tout fonctionne correctement.\n",
        "\n",
        "### Explication Pratique\n",
        "La bonne configuration de l'environnement est cruciale pour garantir la reproductibilit√© et la stabilit√© de vos exp√©riences. En particulier, les versions des biblioth√®ques peuvent influencer le comportement du mod√®le et sa performance, d'o√π l'importance de v√©rifier et documenter ces versions d√®s le d√©but."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code-etape1",
        "outputId": "bb1339f0-25eb-4422-af7b-15b5088ed18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version de TensorFlow : 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Importer les biblioth√®ques n√©cessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Version de TensorFlow :', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question1",
      "metadata": {
        "id": "question1"
      },
      "source": [
        "### Question  1\n",
        "\n",
        "**Q1 :** Pourquoi est-il essentiel de v√©rifier la configuration de l'environnement (versions des biblioth√®ques, d√©pendances, etc.) avant de d√©velopper un mod√®le de deep learning ?\n",
        "\n",
        "_R√©pondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explication :\n",
        "Le deep learning repose sur des biblioth√®ques comme TensorFlow, Keras, NumPy, etc. Ces biblioth√®ques √©voluent constamment avec des mises √† jour qui peuvent :\n",
        "\n",
        "Modifier certaines fonctionnalit√©s,\n",
        "\n",
        "Introduire des incompatibilit√©s entre les versions,\n",
        "\n",
        "Changer le comportement des mod√®les.\n",
        "\n",
        " Pourquoi c'est important ?\n",
        "\n",
        "√âviter les erreurs : Une version incompatible peut emp√™cher le mod√®le de s‚Äôex√©cuter correctement.\n",
        "\n",
        "Assurer la reproductibilit√© : Si une autre personne ex√©cute ton code avec une version diff√©rente, elle peut obtenir des r√©sultats totalement diff√©rents.\n",
        "\n"
      ],
      "metadata": {
        "id": "BNf35UeNcKUd"
      },
      "id": "BNf35UeNcKUd"
    },
    {
      "cell_type": "markdown",
      "id": "etape2",
      "metadata": {
        "id": "etape2"
      },
      "source": [
        "## √âtape 2 : Chargement et Pr√©traitement des Donn√©es\n",
        "\n",
        "Nous allons charger le jeu de donn√©es CIFAR-10, compos√© de 60 000 images couleur r√©parties en 10 classes. Dans cette √©tape, nous normalisons les valeurs des pixels afin qu'elles soient comprises entre 0 et 1, et nous transformons les √©tiquettes en format one-hot pour faciliter le processus de classification.\n",
        "\n",
        "### Explication Pratique\n",
        "La normalisation aide √† stabiliser et acc√©l√©rer l'entra√Ænement du mod√®le en assurant que les valeurs d'entr√©e ont une √©chelle comparable. Le one-hot encoding √©vite que le mod√®le interpr√®te les √©tiquettes comme des valeurs num√©riques ordonn√©es, ce qui est essentiel pour les probl√®mes de classification multi-classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape2",
      "metadata": {
        "id": "code-etape2"
      },
      "outputs": [],
      "source": [
        "# Charger le jeu de donn√©es CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normaliser les valeurs des pixels (entre 0 et 1)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convertir les vecteurs de classes en matrices binaires (one-hot encoding)\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Forme des donn√©es d'entrainement :\", x_train.shape)\n",
        "print(\"Forme des √©tiquettes d'entra√Ænement :\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question2",
      "metadata": {
        "id": "question2"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "**Q2 :** Expliquez comment la normalisation des pixels et le one-hot encoding des √©tiquettes contribuent chacun √† la stabilit√© et √† l'efficacit√© de l'entra√Ænement d'un mod√®le de deep learning.\n",
        "\n",
        "_R√©pondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les images sont compos√©es de pixels avec des valeurs entre 0 et 255.\n",
        "En divisant chaque pixel par 255, on les ram√®ne dans l‚Äôintervalle [0,1], ce qui facilite l‚Äôapprentissage du mod√®le.\n",
        "\n",
        "--> Stabilise l'entra√Ænement : Les valeurs normalis√©es √©vitent des mises √† jour trop brusques des poids du r√©seau.\n",
        "\n",
        "--> Acc√©l√®re la convergence : Le mod√®le apprend plus efficacement car les valeurs sont homog√®nes."
      ],
      "metadata": {
        "id": "Yb1UtoJpdu4w"
      },
      "id": "Yb1UtoJpdu4w"
    },
    {
      "cell_type": "markdown",
      "id": "etape3",
      "metadata": {
        "id": "etape3"
      },
      "source": [
        "## √âtape 3 : Exploration et Visualisation des Donn√©es\n",
        "\n",
        "Avant de construire le mod√®le, il est important d'explorer et de visualiser les donn√©es. Nous affichons ainsi un √©chantillon d'images du jeu de donn√©es pour mieux comprendre leur contenu et la distribution des classes.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation des donn√©es permet d'identifier d'√©ventuelles anomalies, comme des classes sous-repr√©sent√©es ou des images bruit√©es, et de d√©cider si des techniques d'augmentation de donn√©es ou de pr√©traitement suppl√©mentaires sont n√©cessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape3",
      "metadata": {
        "id": "code-etape3"
      },
      "outputs": [],
      "source": [
        "# Afficher quelques images du jeu de donn√©es d'entra√Ænement\n",
        "noms_classes = ['avion', 'automobile', 'oiseau', 'chat', 'cerf',\n",
        "               'chien', 'grenouille', 'cheval', 'navire', 'camion']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(noms_classes[y_train[i].argmax()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question3",
      "metadata": {
        "id": "question3"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "**Q3 :** D'apr√®s la visualisation, discutez de l'impact potentiel d'une distribution in√©gale des classes ou de la pr√©sence d'images de mauvaise qualit√© sur la performance d'un mod√®le de classification. Quelles strat√©gies pourraient √™tre mises en place pour pallier ces probl√®mes ?\n",
        "\n",
        "_R√©pondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Distribution in√©gale des classes (D√©s√©quilibre des donn√©es)\n",
        "Si certaines classes ont beaucoup plus d'exemples que d'autres, le mod√®le aura tendance √† privil√©gier les classes majoritaires, ce qui nuit aux performances.\n",
        "\n",
        " CONSEQUENCES :\n",
        "\n",
        "Mauvaise reconnaissance des classes sous-repr√©sent√©es.\n",
        "\n",
        "Mauvaise g√©n√©ralisation aux nouvelles donn√©es.\n",
        "\n",
        "--> Solutions :\n",
        "\n",
        "Sur-√©chantillonnage : Ajouter des images artificielles des classes minoritaires.\n",
        "\n",
        "Sous-√©chantillonnage : R√©duire le nombre d‚Äôimages des classes majoritaires.\n",
        "\n",
        "Pond√©ration des classes dans la fonction de perte.\n",
        "\n",
        "2. Images de mauvaise qualit√©\n",
        "Les images floues, bruit√©es ou mal expos√©es peuvent fausser l‚Äôapprentissage.\n",
        "\n",
        " CONSEQUENCES :\n",
        "\n",
        "Le mod√®le apprend des informations erron√©es.\n",
        "\n",
        "Les performances sont d√©grad√©es.\n",
        "\n",
        "--> Solutions :\n",
        "\n",
        "Nettoyage des donn√©es : Supprimer ou am√©liorer les images de mauvaise qualit√©.\n",
        "\n",
        "Augmentation de donn√©es : Rotation, zoom, bruit al√©atoire pour rendre le mod√®le plus robuste."
      ],
      "metadata": {
        "id": "DXRbro_GeAQH"
      },
      "id": "DXRbro_GeAQH"
    },
    {
      "cell_type": "markdown",
      "id": "etape4",
      "metadata": {
        "id": "etape4"
      },
      "source": [
        "## √âtape 4 : Construction du Mod√®le CNN\n",
        "\n",
        "Nous allons construire un r√©seau de neurones convolutif (CNN) pour extraire des caract√©ristiques hi√©rarchiques des images. Ce mod√®le se compose de plusieurs blocs de convolution suivis de couches de pooling et se termine par des couches enti√®rement connect√©es pour la classification.\n",
        "\n",
        "### Explication Pratique\n",
        "Les couches de convolution permettent au mod√®le de d√©tecter des motifs locaux (comme les contours ou les textures), tandis que les couches de pooling r√©duisent la dimensionnalit√©, ce qui diminue la charge computationnelle et aide √† rendre le mod√®le plus robuste aux translations. Le dropout, quant √† lui, est une technique de r√©gularisation qui aide √† pr√©venir le surapprentissage en d√©sactivant al√©atoirement certains neurones pendant l'entra√Ænement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape4",
      "metadata": {
        "id": "code-etape4"
      },
      "outputs": [],
      "source": [
        "# Construire le mod√®le CNN\n",
        "model = models.Sequential()\n",
        "\n",
        "# Bloc de convolution 1 : 32 filtres, taille 3x3, activation ReLU\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 2 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 3 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Aplatir les sorties et ajouter des couches enti√®rement connect√©es\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question4",
      "metadata": {
        "id": "question4"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "**Q4 :** D√©crivez le r√¥le de chaque composant du CNN (couches de convolution, pooling et dropout) et expliquez comment ils interagissent pour permettre au mod√®le d'extraire des caract√©ristiques pertinentes des images.\n",
        "\n",
        "_R√©pondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Couches de convolution\n",
        "\n",
        "Elles appliquent des filtres (ou kernels) pour d√©tecter des motifs comme des bords, textures ou formes.\n",
        "\n",
        "Chaque filtre glisse sur l‚Äôimage et extrait des caract√©ristiques locales.\n",
        "\n",
        "Plus il y a de couches, plus le mod√®le d√©tecte des motifs complexes (ex : 1√®re couche ‚Üí bords, 2e couche ‚Üí formes, 3e couche ‚Üí objets).\n",
        "\n",
        "-->Couches de pooling (MaxPooling, AveragePooling)\n",
        "\n",
        "Elles r√©duisent la taille des matrices de caract√©ristiques, ce qui :\n",
        "\n",
        "Diminue le nombre de param√®tres ‚Üí mod√®le plus rapide.\n",
        "\n",
        "Garde les informations importantes tout en supprimant du bruit.\n",
        "\n",
        "Exemple : MaxPooling prend la valeur maximale d‚Äôune r√©gion de pixels (ex: une matrice 2x2 devient un seul pixel, avec la valeur max).\n",
        "\n",
        "-->Couches de Dropout\n",
        "\n",
        "Elles d√©sactivent al√©atoirement un certain pourcentage de neurones pendant l‚Äôentra√Ænement.\n",
        "\n",
        "Cela emp√™che le mod√®le de m√©moriser trop fortement les donn√©es d‚Äôentra√Ænement (√©vite l‚Äôoverfitting).\n",
        "\n",
        "COMMENT CES COUCHES INTERAGISSENT ?\n",
        "\n",
        "Les couches de convolution extraient les caract√©ristiques visuelles.\n",
        "\n",
        "Les couches de pooling r√©duisent la dimension et conservent les informations cl√©s.\n",
        "\n",
        "Le dropout emp√™che le mod√®le de trop s‚Äôadapter aux donn√©es d‚Äôentra√Ænement et le rend plus g√©n√©ralisable aux nouvelles images."
      ],
      "metadata": {
        "id": "l8yohyZmeaEL"
      },
      "id": "l8yohyZmeaEL"
    },
    {
      "cell_type": "markdown",
      "id": "etape5",
      "metadata": {
        "id": "etape5"
      },
      "source": [
        "## √âtape 5 : Compilation et Entra√Ænement du Mod√®le\n",
        "\n",
        "Nous allons maintenant compiler le mod√®le en choisissant un optimiseur, une fonction de perte ainsi que des m√©triques d'√©valuation. Ensuite, nous entra√Ænons le mod√®le sur les donn√©es d'entra√Ænement en r√©servant une partie des donn√©es pour la validation.\n",
        "\n",
        "### Explication Pratique\n",
        "La compilation configure le processus d'apprentissage, notamment la mani√®re dont les poids seront ajust√©s via la r√©tropropagation. Le choix de l'optimiseur (ici, Adam) et la d√©finition des hyperparam√®tres (comme le taux d'apprentissage et la taille du batch) influencent grandement la vitesse de convergence et la qualit√© finale du mod√®le."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape5",
      "metadata": {
        "id": "code-etape5"
      },
      "outputs": [],
      "source": [
        "# Compiler le mod√®le\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entra√Æner le mod√®le\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question5",
      "metadata": {
        "id": "question5"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "**Q5 :** Quels sont les effets d'un choix inadapt√© d'hyperparam√®tres (comme le taux d'apprentissage ou la taille du batch) sur l'entra√Ænement d'un r√©seau de neurones ? Expliquez en quoi un optimiseur bien configur√© est crucial pour la convergence du mod√®le.\n",
        "\n",
        "_R√©pondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "-->Un taux d‚Äôapprentissage trop √©lev√© peut entra√Æner une divergence du mod√®le, le faisant osciller sans converger.\n",
        "\n",
        "-->Un taux d‚Äôapprentissage trop faible peut ralentir l'entra√Ænement et emp√™cher le mod√®le d'atteindre un bon minimum.\n",
        "\n",
        "-->Une taille de batch trop grande peut exiger trop de m√©moire et moyenner les gradients, ce qui peut emp√™cher d‚Äôapprendre des variations subtiles.\n",
        "\n",
        "-->Une taille de batch trop petite peut causer des mises √† jour instables des poids du r√©seau.\n",
        "\n",
        "ROLE DE l'OPTIMISEUR:\n",
        "Un bon optimiseur (comme Adam, RMSprop ou SGD) aide le mod√®le √† trouver efficacement le minimum de la fonction de perte, assurant une convergence stable et rapide."
      ],
      "metadata": {
        "id": "P2rHNvJpfDA0"
      },
      "id": "P2rHNvJpfDA0"
    },
    {
      "cell_type": "markdown",
      "id": "etape6",
      "metadata": {
        "id": "etape6"
      },
      "source": [
        "## √âtape 6 : √âvaluation du Mod√®le\n",
        "\n",
        "Apr√®s l'entra√Ænement, nous √©valuons notre mod√®le sur le jeu de test afin de mesurer sa capacit√© de g√©n√©ralisation sur des donn√©es in√©dites. Les m√©triques telles que la perte et la pr√©cision nous aident √† quantifier la performance globale du mod√®le.\n",
        "\n",
        "### Explication Pratique\n",
        "L'√©valuation sur un jeu de test ind√©pendant permet de d√©tecter un √©ventuel surapprentissage (overfitting). Si le mod√®le pr√©sente une bonne performance sur l'entra√Ænement mais une performance m√©diocre sur le test, cela indique qu'il n'a pas suffisamment g√©n√©ralis√©, ce qui peut n√©cessiter des ajustements comme plus de r√©gularisation ou des techniques d'augmentation de donn√©es."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape6",
      "metadata": {
        "id": "code-etape6"
      },
      "outputs": [],
      "source": [
        "# √âvaluer le mod√®le sur le jeu de test\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Pr√©cision sur le jeu de test :', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question6",
      "metadata": {
        "id": "question6"
      },
      "source": [
        "### Question  6\n",
        "\n",
        "**Q6 :** Que nous indiquent la perte et la pr√©cision obtenues lors de l'√©valuation sur le jeu de test ? Quels ajustements pourriez-vous envisager si vous observez un √©cart significatif entre les performances sur l'entra√Ænement et le test ?\n",
        "\n",
        "_R√©pondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Une perte et une pr√©cision √©lev√©es sur l'entra√Ænement, mais faibles sur le test  Overfitting (sur-apprentissage).\n",
        "\n",
        "Une perte √©lev√©e √† la fois sur l'entra√Ænement et le test ‚Üí Underfitting (mod√®le trop simple, qui n'apprend pas bien).\n",
        "\n",
        "AJUSTEMENT POSSIBLES :\n",
        "\n",
        "-->Si overfitting :\n",
        "\n",
        "Ajouter du dropout pour √©viter la d√©pendance excessive √† certaines caract√©ristiques.\n",
        "\n",
        "R√©duire la complexit√© du mod√®le (moins de couches ou de neurones).\n",
        "\n",
        "Augmenter les donn√©es d‚Äôentra√Ænement (data augmentation).\n",
        "\n",
        "-->Si underfitting :\n",
        "\n",
        "Utiliser un mod√®le plus complexe (plus de couches, plus de neurones).\n",
        "\n",
        "Entra√Æner plus longtemps.\n",
        "\n",
        "Changer l‚Äôoptimiseur ou le taux d‚Äôapprentissage.\n",
        "\n"
      ],
      "metadata": {
        "id": "bALJ7ywEfWQH"
      },
      "id": "bALJ7ywEfWQH"
    },
    {
      "cell_type": "markdown",
      "id": "etape7",
      "metadata": {
        "id": "etape7"
      },
      "source": [
        "## √âtape 7 : Pr√©dictions et Visualisation des R√©sultats\n",
        "\n",
        "Nous allons utiliser le mod√®le entra√Æn√© pour pr√©dire les classes des images du jeu de test. La visualisation des r√©sultats nous permet de comparer les √©tiquettes pr√©dites aux √©tiquettes r√©elles et d'identifier les erreurs potentielles.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation aide √† comprendre qualitativement comment le mod√®le se comporte face √† diff√©rentes images. Cela permet d'identifier si certaines classes sont syst√©matiquement mal pr√©dites ou si le mod√®le confond certaines cat√©gories, ouvrant ainsi la voie √† des am√©liorations ult√©rieures (par exemple, via l'augmentation de donn√©es ou des ajustements de l'architecture)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "code-etape7",
      "metadata": {
        "id": "code-etape7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "d5bd229f-861b-42ea-d745-8a14a69ec432"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-49b5e0190f2a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Faire des pr√©dictions sur le jeu de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fonction pour afficher l'image avec les √©tiquettes pr√©dites et r√©elles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mafficher_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquette_vraie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# Faire des pr√©dictions sur le jeu de test\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Fonction pour afficher l'image avec les √©tiquettes pr√©dites et r√©elles\n",
        "def afficher_image(i, predictions_array, etiquette_vraie, img):\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    etiquette_predite = np.argmax(predictions_array)\n",
        "    etiquette_vraie = np.argmax(etiquette_vraie)\n",
        "\n",
        "    couleur = 'blue' if etiquette_predite == etiquette_vraie else 'red'\n",
        "    plt.xlabel(f\"Pr√©dit : {noms_classes[etiquette_predite]} (Vrai : {noms_classes[etiquette_vraie]})\", color=couleur)\n",
        "\n",
        "# Afficher quelques images de test avec leurs pr√©dictions\n",
        "nb_lignes = 5\n",
        "nb_colonnes = 3\n",
        "nb_images = nb_lignes * nb_colonnes\n",
        "plt.figure(figsize=(2 * nb_colonnes, 2 * nb_lignes))\n",
        "for i in range(nb_images):\n",
        "    plt.subplot(nb_lignes, nb_colonnes, i+1)\n",
        "    afficher_image(i, predictions[i], y_test[i], x_test[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question7",
      "metadata": {
        "id": "question7"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "**Q7 :** Apr√®s avoir examin√© les pr√©dictions, identifiez et discutez des strat√©gies conceptuelles (par exemple, l'augmentation de donn√©es, le raffinement de l'architecture ou l'ajustement des hyperparam√®tres) qui pourraient am√©liorer la robustesse et la pr√©cision du mod√®le.\n",
        "\n",
        "_R√©pondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour am√©liorer la robustesse et la pr√©cision du mod√®le apr√®s analyse des pr√©dictions, il est possible d‚Äôexplorer plusieurs strat√©gies :\n",
        "\n",
        "--> L‚Äôaugmentation de donn√©es permet d‚Äôam√©liorer la g√©n√©ralisation.\n",
        "\n",
        "--> Le raffinement de l‚Äôarchitecture optimise la capacit√© d‚Äôapprentissage.\n",
        "\n",
        "--> L‚Äôajustement des hyperparam√®tres stabilise et acc√©l√®re l‚Äôapprentissage.\n",
        "\n",
        "--> Le Transfer Learning permet d‚Äôexploiter des mod√®les puissants d√©j√† entra√Æn√©s.\n",
        "\n",
        "--> La r√©duction du sur-apprentissage garantit une meilleure adaptation aux nouvelles donn√©es.\n",
        "\n",
        "En combinant ces diff√©rentes approches, on peut obtenir un mod√®le plus performant, plus fiable et mieux adapt√© aux d√©fis du monde r√©el. üöÄ"
      ],
      "metadata": {
        "id": "JRlewlhDjbk9"
      },
      "id": "JRlewlhDjbk9"
    },
    {
      "cell_type": "markdown",
      "id": "etape8",
      "metadata": {
        "id": "etape8"
      },
      "source": [
        "## √âtape 8 : Conclusion et Travaux Futurs\n",
        "\n",
        "Dans ce notebook, nous avons :\n",
        "- Configur√© l'environnement et import√© les biblioth√®ques n√©cessaires\n",
        "- Charg√© et pr√©trait√© le jeu de donn√©es CIFAR-10\n",
        "- Explor√© et visualis√© les donn√©es\n",
        "- Construit, compil√© et entra√Æn√© un mod√®le CNN\n",
        "- √âvalu√© le mod√®le et visualis√© ses pr√©dictions\n",
        "\n",
        "### Explication Pratique\n",
        "Ce pipeline offre une approche compl√®te, √† la fois pratique et conceptuelle, pour la mise en ≈ìuvre d'un mod√®le de vision par ordinateur. Pour aller plus loin, vous pouvez explorer des architectures plus complexes, appliquer des techniques d'augmentation de donn√©es ou encore exp√©rimenter avec diff√©rents optimisateurs afin de mieux comprendre l'impact de chacun sur la performance du mod√®le."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}